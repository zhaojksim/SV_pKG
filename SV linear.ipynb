{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1457a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import root_scalar\n",
    "from scipy.special import beta\n",
    "from scipy.special import comb\n",
    "import qmcpy\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import math\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd8c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling function\n",
    "def int_sin_m(x, m):\n",
    "    if m == 0:\n",
    "        return x\n",
    "    elif m == 1:\n",
    "        return 1 - np.cos(x)\n",
    "    else:\n",
    "        return (m - 1) / m * int_sin_m(x, m - 2) - np.cos(x) * np.sin(x) ** (\n",
    "                m - 1\n",
    "        ) / m\n",
    "\n",
    "def zero_sum_projection(d):\n",
    "    basis = np.array([[1.0] * i + [-i] + [0.0] * (d - i - 1) for i in range(1, d)])\n",
    "    return np.array([v / np.linalg.norm(v) for v in basis])\n",
    "\n",
    "\n",
    "def bm_sphere_points(n, d):\n",
    "    import qmcpy\n",
    "    mod = d%2\n",
    "    if mod == 1:\n",
    "        dim = d+1\n",
    "        pairs = dim//2\n",
    "    else:\n",
    "        dim = d\n",
    "        pairs = dim//2\n",
    "    X = qmcpy.Sobol(dim, graycode=True).gen_samples(n)\n",
    "    Y = np.zeros((n, dim))\n",
    "    for i in range(pairs):\n",
    "        R = np.sqrt(-2 * np.log(X[:, 2*i]))\n",
    "        Theta = 2 * np.pi *X[:, 2*i+1]\n",
    "        Y[:, 2*i] = R * np.cos(Theta)\n",
    "        Y[:, 2*i+1] = R * np.sin(Theta)\n",
    "    Y = Y[:, :d]\n",
    "    A = np.sum(Y**2, axis = 1)\n",
    "    B = np.tile(A.reshape(n, 1), (1,d))\n",
    "    Y = Y/np.sqrt(B)\n",
    "    return Y\n",
    "\n",
    "def tfww_sphere_points(n, d):\n",
    "    import qmcpy\n",
    "    X = qmcpy.Sobol(d-1, graycode=True).gen_samples(n)\n",
    "    dim = d\n",
    "    mod = dim%2\n",
    "    if mod == 1:\n",
    "        m = dim//2\n",
    "        g = np.zeros((n, m+1))\n",
    "        c = np.zeros((n, m))\n",
    "        g[:, 0] = 0\n",
    "        g[:, m] = 1\n",
    "        for j in range(m-1):\n",
    "            g[:, m-j-1] = g[:, m-j]*np.power(X[:, m-j-2],2/(2*(m-j-1)+1))\n",
    "            c[:, m-j-1] = np.sqrt(g[:, m-j]-g[:, m-j-1])\n",
    "        c[:, 0] = np.sqrt(g[:, 1] - g[:, 0])\n",
    "        Y = np.zeros((n, dim))\n",
    "        Y[:, 0] = c[:, 0]*(1-2*X[:, m-1])\n",
    "        Y[:, 1] = 2*c[:, 0]*np.sqrt(X[:, m-1]*(1-X[:, m-1]))*np.cos(X[:, m] * 2 * np.pi)\n",
    "        Y[:, 2] = 2*c[:, 0]*np.sqrt(X[:, m-1]*(1-X[:, m-1]))*np.sin(X[:, m] * 2 * np.pi)\n",
    "        for l in range(m-1):\n",
    "            Y[:, 2*l+3] = c[:, l+1]*np.cos(X[:, m+l+1] * 2 * np.pi)\n",
    "            Y[:, 2*l+4] = c[:, l+1]*np.sin(X[:, m+l+1] * 2 * np.pi)\n",
    "    else:\n",
    "        m = dim//2\n",
    "        g = np.zeros((n, m+1))\n",
    "        c = np.zeros((n, m))\n",
    "        g[:, 0] = 0\n",
    "        g[:, m] = 1\n",
    "        for j in range(m-1):\n",
    "            g[:, m-j-1] = g[:, m-j]*np.power(X[:, m-j-2],1/(m-j-1))\n",
    "            c[:, m-j-1] = np.sqrt(g[:, m-j]-g[:, m-j-1])\n",
    "        c[:, 0] = np.sqrt(g[:, 1] - g[:, 0])\n",
    "        Y = np.zeros((n, d))\n",
    "        for l in range(m):\n",
    "            Y[:, 2*l] = c[:, l]*np.cos(X[:, m+l-1] * 2 * np.pi)\n",
    "            Y[:, 2*l+1] = c[:, l]*np.sin(X[:, m+l-1] * 2 * np.pi)\n",
    "    return Y\n",
    "\n",
    "def sct_sphere_points(n, d):\n",
    "    import qmcpy\n",
    "    X = qmcpy.Sobol(d - 1, graycode=True).gen_samples(n)\n",
    "    n = X.shape[0]\n",
    "    Y = np.ones((n, d))\n",
    "    for i in range(n):\n",
    "        Y[i][0] *= np.sin(X[i, 0] * 2 * np.pi)\n",
    "        Y[i][1] *= np.cos(X[i, 0] * 2 * np.pi)\n",
    "\n",
    "    for j in range(2, d):\n",
    "        inv_beta = 1 / beta(j / 2, 1 / 2)\n",
    "        for i in range(n):\n",
    "            root_function = lambda varphi: inv_beta * int_sin_m(varphi, j - 1) - X[i, j - 1]\n",
    "            deg = root_scalar(root_function, bracket=[0, np.pi], xtol=1e-15).root\n",
    "            for k in range(j):\n",
    "                Y[i][k] *= np.sin(deg)\n",
    "            Y[i][j] *= np.cos(deg)\n",
    "    return Y\n",
    "\n",
    "def gen_sobol_permutations(n, d, method):\n",
    "    if method == \"bm\":\n",
    "        sphere_points = bm_sphere_points(n, d - 1)\n",
    "    elif method == \"tfww\":\n",
    "        sphere_points = tfww_sphere_points(n, d - 1)\n",
    "    else:\n",
    "        sphere_points = sct_sphere_points(n, d - 1)\n",
    "    basis = zero_sum_projection(d)\n",
    "    projected_sphere_points = sphere_points.dot(basis)\n",
    "    p = np.zeros((n, d), dtype=np.int64)\n",
    "    for i in range(n):\n",
    "        p[i] = np.argsort(projected_sphere_points[i])\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab310eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the model parameters\n",
    "class bayesian_network_posterior:\n",
    "    def __init__(self, the_R, tau2_R, kap_R, lam_R, mu, num_state, num_action, n_time, beta, v2):\n",
    "        self.the_R = the_R\n",
    "        self.tau2_R = tau2_R\n",
    "        self.kap_R = kap_R\n",
    "        self.lam_R = lam_R\n",
    "        self.num_nodes = (num_state + num_action) * n_time\n",
    "        self.num_state = num_state\n",
    "        self.num_action = num_action\n",
    "        self.mu = mu\n",
    "        self.beta = beta\n",
    "        self.v2 = v2\n",
    "        self.n_time = n_time\n",
    "\n",
    "    def posterior_sample(self, size=1, useFixed = True):\n",
    "        p_beta = np.zeros(shape=(self.num_nodes,self.num_nodes, size))\n",
    "        p_v2 = np.zeros(shape=(self.num_nodes, size))\n",
    "        for i in range(self.num_nodes):\n",
    "            for j in range(self.num_nodes):\n",
    "                if self.tau2_R[i, j] != 0:\n",
    "                    p_beta[i, j, ] = np.random.normal(loc=self.the_R[i,j], scale=np.sqrt(self.tau2_R[i,j]), size=size)\n",
    "            gamma_rate = self.lam_R[i] / 2\n",
    "            p_v2[i,] = 1 / np.random.gamma(shape=self.kap_R[i] / 2, scale=1/gamma_rate, size=size)\n",
    "        if useFixed:\n",
    "            p_beta = self.beta\n",
    "            p_v2 = self.v2\n",
    "        return (p_beta, p_v2, self.mu)\n",
    "\n",
    "class bayesian_network:\n",
    "    def __init__(self, mu, beta, v2, num_action, num_state, n_time, normalized = True, sample_mean=None, sample_sd=None):\n",
    "        self.n_time = n_time\n",
    "        if normalized:\n",
    "            self.sample_mean = sample_mean\n",
    "            self.sample_sd = sample_sd\n",
    "            self.normalized = True\n",
    "        self.initial_state_full = np.array([0.05, 0.00, 0.00, 30.00, 5.00,0.7])\n",
    "        if num_state == 4:\n",
    "            self.initial_state_base = self.initial_state_full[[0, 1, 3, 4, 5]]\n",
    "        if num_state == 5:\n",
    "            self.initial_state_base = self.initial_state_full\n",
    "        self.mu = mu\n",
    "        self.v2 = v2\n",
    "        self.beta = beta\n",
    "        self.num_action = num_action\n",
    "        self.num_state = num_state\n",
    "        self.n_factor = num_action + num_state\n",
    "        self.beta_state = np.zeros(shape=(n_time, num_state, num_state)) # s -> s\n",
    "        self.beta_action = np.zeros(shape=(n_time, num_action, num_state)) # a -> s\n",
    "        for i in range(n_time-1):\n",
    "            self.beta_state[i,:,:] = beta[(self.n_factor * (i+1) - num_state):(self.n_factor * (i+1)), (self.n_factor * (i + 2) - num_state): (self.n_factor * (i + 2))]\n",
    "            self.beta_action[i,:,:] = beta[(self.n_factor * i):(self.n_factor * i + self.num_action), (self.n_factor * (i + 2) - num_state):(self.n_factor * (i + 2))]\n",
    "        self.mu_a = []\n",
    "        for i in range(self.n_time):\n",
    "            temp_list = []\n",
    "            for j in range(self.num_action):\n",
    "                temp_list.append(self.mu[i * self.n_factor + j])\n",
    "            self.mu_a.append(temp_list)\n",
    "\n",
    "    def initial_state_generator(self, scale=10):\n",
    "        init_states = self.initial_state_base + np.abs(np.random.normal(0, np.array(self.initial_state_base)/scale + 0.01))\n",
    "        init_states = init_states[[0,1,3,4,5]] # init_states[:-1] * init_states[-1]\n",
    "        self.initial_state = (init_states - self.sample_mean[(self.n_factor - self.num_state):self.n_factor]) / self.sample_sd[(self.n_factor - self.num_state):self.n_factor]\n",
    "\n",
    "    def rescale_action(self, action, t, scale_method = \"standard\"):\n",
    "        if not self.normalized:\n",
    "            return action\n",
    "        if scale_method == \"standard\":\n",
    "            return self.sample_sd[(self.n_factor * t):(self.n_factor * t + self.num_action)] * action + self.sample_mean[(self.n_factor * t):(self.n_factor * t + self.num_action)]\n",
    "        else:\n",
    "            return self.sample_sd[(self.n_factor * t):(self.n_factor * t + self.num_action)] * action\n",
    "\n",
    "    def rescale_state(self, state, t, scale_method = \"standard\"):\n",
    "        if not self.normalized:\n",
    "            return state\n",
    "        if scale_method == \"standard\":\n",
    "            return self.sample_sd[(self.n_factor * (t+1) - self.num_state):(self.n_factor * (t+1))] * state + self.sample_mean[(self.n_factor * (t+1) - self.num_state):(self.n_factor * (t+1))]\n",
    "        else:\n",
    "            return self.sample_sd[(self.n_factor * (t+1) - self.num_state):(self.n_factor * (t+1))] * state\n",
    "        \n",
    "beta_gibbs = pd.read_csv('data/beta_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "v2_gibbs = pd.read_csv('data/v2_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None,\n",
    "                        dtype=np.float64)\n",
    "the_R = pd.read_csv('data/the_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "tau2_R = pd.read_csv('data/tau2_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "kap_R = pd.read_csv('data/kap_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "lam_R = pd.read_csv('data/lam_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "mu = pd.read_csv('data/mu_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "sd = pd.read_csv('data/sd_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "bn_post = bayesian_network_posterior(the_R.to_numpy(), tau2_R.to_numpy(), kap_R.to_numpy(), lam_R.to_numpy(),\n",
    "                                         mu.to_numpy().flatten(), 5, 1, 36, beta_gibbs, v2_gibbs)\n",
    "# mua = np.array(mu.to_numpy().reshape(36, 6)[:, 0]).reshape(1, 36)\n",
    "# mus = np.array(mu.to_numpy().reshape(36, 6)[:, 1:]).reshape(5, 36)\n",
    "\n",
    "def simulate(H = 36, nums = 5, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "    V_mat = np.zeros((H*nums, H*nums))\n",
    "    mat = (2*np.random.rand((H-1)*nums, (H-1)*nums)-1)/5\n",
    "    V_mat[nums*1:nums*H, nums*1:nums*H] = mat.dot(mat.T)\n",
    "    return V_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f011ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_action(action, t, mu, sd, scale_method = \"standard\"):\n",
    "    mu0 = mu.to_numpy().flatten()\n",
    "    sample_sd = sd.to_numpy().flatten()\n",
    "    a_t = sample_sd[(6 * t):(6 * t + 1)] * action + mu0[(6 * t):(6 * t + 1)]\n",
    "    return a_t\n",
    "\n",
    "# mean function and variance function\n",
    "def cal_mean(s1, mus, mua, mu, sd, betaa, betas, theta, b_r, c_r):\n",
    "    H = np.shape(mus)[1]\n",
    "    nums =np.shape(mus)[0]\n",
    "    s = np.zeros((nums, H-1))\n",
    "    a = np.zeros(H)\n",
    "    R = np.identity(nums)\n",
    "    theta_0 = np.concatenate((theta, np.zeros((nums, 1))), axis = 1)\n",
    "    m_r = 0\n",
    "    for i in range(H-1):\n",
    "        coe = np.transpose(betas[:,:,i] + theta[:,i].reshape(nums, 1).dot(betaa[:,i].reshape(1, nums)))\n",
    "        R = coe.dot(R)\n",
    "        si = mus[:, i+1].reshape(nums, 1) + R.dot(s1.reshape(nums,1) - mus[:, 0].reshape(nums,1))\n",
    "        s[:, i] = si.reshape(nums)\n",
    "    s = np.concatenate((s1.reshape(nums, 1), s), axis = 1)\n",
    "    for i in range(H-1):\n",
    "        temp_a = mua[0, i] + np.sum(theta_0[:, i]*(s[:, i]-mus[:, i]))\n",
    "        a[i] = rescale_action(temp_a, i, mu, sd)\n",
    "        m_r = m_r-534.52*a[i]\n",
    "    m_r = m_r + np.sum(1.29*s[1,H-1])\n",
    "    return [m_r, s]\n",
    "\n",
    "def cal_var(betaa, betas, theta, b_r, c_r, V_mat):\n",
    "    nums = np.shape(theta)[0]\n",
    "    H = np.shape(theta)[1]+1    \n",
    "    # calculate the R matrix\n",
    "    R = np.zeros(((H-1)*nums, (H-1)*nums))\n",
    "    for t2 in range(H-1):\n",
    "        R0 = np.identity(nums)\n",
    "        for t1 in range(0, t2+1):\n",
    "            R0 = R0.dot(np.transpose(betas[:,:, t2-t1]+theta[:, t2-t1].reshape(nums, 1).dot(betaa[:, t2-t1].reshape(1,nums))))\n",
    "            R[nums*(t2-t1):nums*(t2-t1+1), nums*t2:nums*(t2+1)] = R0\n",
    "    # calculate the covariance matrix\n",
    "    A1 = np.zeros((H*nums, H*nums))\n",
    "    A2 = np.zeros((H*nums, H*nums))\n",
    "    A3 = np.zeros((H*nums, H*nums))\n",
    "    cov = np.zeros((H*nums, H*nums))\n",
    "    for t2 in range(H-1):\n",
    "        for t1 in range(t2+1): \n",
    "            A1[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)] = (A1[nums*(t1+1):nums*(t1+2), nums*t2:nums*(t2+1)]+A2[nums*(t1+1):nums*(t1+2), nums*t2:nums*(t2+1)]).dot(R[nums*t2:nums*(t2+1), nums*t2:nums*(t2+1)].T)\n",
    "            A1[nums*(t2+1):nums*(t2+2), nums*(t1+1):nums*(t1+2)] = A1[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)].T\n",
    "            A2[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)] = R[nums*t1:nums*(t1+1), nums*t1:nums*(t1+1)].dot(A2[nums*(t1):nums*(t1+1), nums*(t2+1):nums*(t2+2)]+V_mat[nums*(t1):nums*(t1+1), nums*(t2+1):nums*(t2+2)])\n",
    "            A2[nums*(t2+1):nums*(t2+2), nums*(t1+1):nums*(t1+2)] = A2[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)].T\n",
    "            A3[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)] = (A3[nums*(t1+1):nums*(t1+2), nums*(t2):nums*(t2+1)]+V_mat[nums*(t1+1):nums*(t1+2), nums*(t2):nums*(t2+1)]).dot(R[nums*t2:nums*(t2+1), nums*t2:nums*(t2+1)].T)\n",
    "            A3[nums*(t2+1):nums*(t2+2), nums*(t1+1):nums*(t1+2)] = A3[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)].T\n",
    "            cov[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)] = A1[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)]+A2[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)]+A3[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)]+V_mat[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)]\n",
    "            cov[nums*(t2+1):nums*(t2+2), nums*(t1+1):nums*(t1+2)] = cov[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)]\n",
    "    # calculate the variance of the cumulative rewards\n",
    "    v_r = 0\n",
    "    theta_0 = np.concatenate((theta, np.zeros((nums, 1))), axis = 1)\n",
    "    for t2 in range(H-1):\n",
    "        for t1 in range(H-1):\n",
    "            alpha1 = (b_r[t1+1]*(theta_0[:,t1+1].reshape(1, nums))+c_r[:, t1+1].reshape(1,nums))/400\n",
    "            alpha2 = (b_r[t2+1]*(theta_0[:,t2+1].reshape(1, nums))+c_r[:, t2+1].reshape(1,nums))/400        \n",
    "            v_r = v_r+alpha1.dot(cov[nums*(t1+1):nums*(t1+2), nums*(t2+1):nums*(t2+2)]).dot(alpha2.T)\n",
    "    return [v_r, cov]\n",
    "\n",
    "# QMC for shapley value\n",
    "def QMC_mean(s1, mus, mua, mu, sd, betaa, betas, theta, b_r, c_r, P):\n",
    "    # calculate approximate shapley value using QMC\n",
    "    m = np.shape(P)[0]\n",
    "    nums = np.shape(theta)[0]\n",
    "    H = np.shape(theta)[1]+1\n",
    "    num_th = nums*(H-1)\n",
    "    shap_value_r = np.zeros((num_th))\n",
    "    shap_value_s = np.zeros((num_th, nums, H))\n",
    "    theta_flat = theta.flatten()\n",
    "    for i in range(m):\n",
    "        permute = P[i,:]\n",
    "        temp = np.zeros(num_th)\n",
    "        [r_prev, s_prev] = cal_mean(s1, mus, mua, mu, sd, betaa, betas, temp.reshape(nums, H-1), b_r, c_r)\n",
    "        for j in range(num_th):\n",
    "            index = permute[j]\n",
    "            temp[index] = theta_flat[index].copy()\n",
    "            [r, s] = cal_mean(s1, mus, mua, mu, sd, betaa, betas, temp.reshape(nums, H-1), b_r, c_r)\n",
    "            shap_value_r[index] = shap_value_r[index]+(r - r_prev)\n",
    "            shap_value_s[index,:,:] = shap_value_s[index]+(s - s_prev)\n",
    "            [r_prev, s_prev] = [r.copy(), s.copy()]\n",
    "#             shap_value[index, :, :] = shap_value[index, :, :] + (v1 - v0).reshape(nums, H-1)\n",
    "    shap_value_r = shap_value_r/m\n",
    "    shap_value_s = shap_value_s/m    \n",
    "    return [shap_value_r, shap_value_s]\n",
    "\n",
    "def QMC_var(betaa, betas, theta, b_r, c_r, V_mat, P):\n",
    "    # calculate approximate shapley value using QMC\n",
    "    m = np.shape(P)[0]\n",
    "    nums = np.shape(theta)[0]\n",
    "    H = np.shape(theta)[1]+1\n",
    "    num_th = nums*(H-1)\n",
    "    shap_value_r = np.zeros((num_th))\n",
    "    shap_value_s = np.zeros((num_th, nums, H))\n",
    "    theta_flat = theta.flatten()\n",
    "    for i in range(m):\n",
    "        permute = P[i,:]\n",
    "        temp = np.zeros(num_th)\n",
    "        for j in range(num_th):\n",
    "            index = permute[j]\n",
    "            [vr_prev, cov_prev] = cal_var(betaa, betas, temp.reshape(nums, H-1),b_r, c_r, V_mat)\n",
    "            vs_prev = cov_prev.diagonal().reshape(nums,H,order='F')\n",
    "            temp[index] = theta_flat[index].copy()\n",
    "            [vr, cov] = cal_var(betaa, betas, temp.reshape(nums, H-1),b_r, c_r, V_mat)\n",
    "            vs = cov.diagonal().reshape(nums,H,order='F')\n",
    "            shap_value_r[index] = shap_value_r[index]+(vr - vr_prev)\n",
    "            shap_value_s[index,:,:] = shap_value_s[index]+(vs - vs_prev)\n",
    "#             shap_value[index, :, :] = shap_value[index, :, :] + (v1 - v0).reshape(nums, H-1)\n",
    "    shap_value_r = shap_value_r/m\n",
    "    shap_value_s = shap_value_s/m    \n",
    "    return [shap_value_r, shap_value_s]\n",
    "\n",
    "def cal_mean_theta(p_beta0, p_v20, mu0, mu, sd, s1, theta, b_r, c_r, P):\n",
    "    beta = p_beta0\n",
    "    v2 = p_v20\n",
    "    bn = bayesian_network(mu0, beta, v2, 1, 5, 36, True, mu, sd.to_numpy().flatten())\n",
    "    mua = np.array(bn.mu_a).reshape(1, 36)\n",
    "    mus = np.array(bn.mu.reshape(36, 6)[:,1:]).reshape(5,36)\n",
    "    betas = np.zeros((5, 5, 36))\n",
    "    for i in range(36):\n",
    "        betas[:,:,i] = bn.beta_state[i,:,:]\n",
    "    betaa = np.transpose(bn.beta_action.reshape(36,5))\n",
    "    [shap_mean_r, shap_mean_s] = QMC_mean(s1, mus, mua, mu, sd, betaa, betas, theta, b_r, c_r, P)\n",
    "    return [shap_mean_r, shap_mean_s]\n",
    "\n",
    "def cal_var_theta(p_beta0, p_v20, mu0, mu, sd, theta, b_r, c_r, V_mat, P):\n",
    "    beta = p_beta0\n",
    "    v2 = p_v20\n",
    "    k = 0\n",
    "    for i in range(216):\n",
    "        if i%6 != 0:\n",
    "            V_mat[k,k] = v2[i]\n",
    "            k = k+1   \n",
    "    bn = bayesian_network(mu0, beta, v2, 1, 5, 36, True, mu, sd.to_numpy().flatten())\n",
    "    betas = np.zeros((5, 5, 36))\n",
    "    for i in range(36):\n",
    "        betas[:,:,i] = bn.beta_state[i,:,:]\n",
    "    betaa = np.transpose(bn.beta_action.reshape(36,5))\n",
    "    [shap_var_r, shap_var_s] = QMC_var(betaa, betas, theta, b_r, c_r, V_mat, P)\n",
    "    return [shap_var_r, shap_var_s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da1273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the predictive shapley value\n",
    "# sample from the parameters\n",
    "ssize1 = 200\n",
    "p_beta, p_v2, mu0 = bn_post.posterior_sample(ssize1, useFixed=False)\n",
    "mu = pd.read_csv('data/mu_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "s1 = np.array([0.05,0,30,5,0.7])\n",
    "theta = np.load('theta.npy')\n",
    "b_r = np.repeat(-534.52, 36)\n",
    "c_r = np.zeros((5, 36))\n",
    "c_r[1, 35] = 1.29\n",
    "m1 = 500\n",
    "nums = 5\n",
    "H = 36\n",
    "\n",
    "# sample the permutations\n",
    "P = np.zeros((ssize1, m1, nums * (H-1)), dtype=np.int64)\n",
    "for i in range(ssize1):\n",
    "    P_i = gen_sobol_permutations(m1, nums * (H-1), \"tfww\")\n",
    "    P[i, :, :] = P_i\n",
    "\n",
    "start = time.time()\n",
    "print(1)\n",
    "shap_mean_theta_list = []\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "for i in range(ssize1):\n",
    "    shap_mean_theta_list.append(pool.apply_async(cal_mean_theta, args = (p_beta[:, :, i], p_v2[:, i], mu0, mu, sd, s1, theta, b_r, c_r, P[i, :, :])))\n",
    "pool.close()\n",
    "pool.join()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "shap_mean_r_samples = np.zeros((ssize1, 175))\n",
    "shap_mean_s_samples = np.zeros((ssize1, 175, nums, H))\n",
    "for i in range(ssize1):\n",
    "    shap_mean_r_samples[i, :] = shap_mean_theta_list[i].get()[0]\n",
    "    shap_mean_s_samples[i, :, :, :] = shap_mean_theta_list[i].get()[1]\n",
    "\n",
    "np.save('linear_shap_mean_r_theta_samples.npy', shap_mean_r_samples)\n",
    "np.save('linear_shap_mean_s_theta_samples.npy', shap_mean_s_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22cb936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the variance-based Shapley value\n",
    "\n",
    "V_mat = simulate(H = 36, nums = 5, seed = 1)\n",
    "\n",
    "# calculate the variance-based shapley value\n",
    "# sample from the parameters\n",
    "ssize2 = 200\n",
    "m2 = 500\n",
    "p_beta, p_v2, mu0 = bn_post.posterior_sample(ssize2, useFixed=False)\n",
    "mu = pd.read_csv('data/mu_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "s1 = np.array([0.00000000e+00,0.00000000e+00,3.00000000e+01,5.00000000e+00,7.00000000e-01])\n",
    "theta = np.load('theta.npy')\n",
    "b_r = np.repeat(-534.52, 36)\n",
    "c_r = np.zeros((5, 36))\n",
    "c_r[1, 35] = 1.29\n",
    "\n",
    "\n",
    "# sample the permutations\n",
    "P = np.zeros((ssize2, m2, nums * (H-1)), dtype=np.int64)\n",
    "for i in range(ssize2):\n",
    "    P_i = gen_sobol_permutations(m2, nums * (H-1), \"tfww\")\n",
    "    P[i, :, :] = P_i\n",
    "\n",
    "start = time.time()\n",
    "print(1)\n",
    "shap_var_theta_list = []\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "for i in range(ssize2):\n",
    "    shap_var_theta_list.append(pool.apply_async(cal_var_theta, args = (p_beta[:, :, i], p_v2[:, i], mu0, mu, sd, theta, b_r, c_r, V_mat, P[i, :, :])))\n",
    "pool.close()\n",
    "pool.join()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "shap_var_r_samples = np.zeros((ssize2, 175))\n",
    "shap_var_s_samples = np.zeros((ssize2, 175, nums, H))\n",
    "for i in range(ssize2):\n",
    "    shap_var_r_samples[i, :] = shap_var_theta_list[i].get()[0]\n",
    "    shap_var_s_samples[i, :, :, :] = shap_var_theta_list[i].get()[1]\n",
    "\n",
    "np.save('linear_shap_var_r_theta_samples.npy', shap_var_r_samples)\n",
    "np.save('linear_shap_var_s_theta_samples.npy', shap_var_s_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cddc074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mean_random(s1, mu0, mu, sd, p_beta0, v20, theta, b_r, c_r):\n",
    "    v2 = np.array(v20.reshape(36, 6)[:, 1:]).reshape(5, 36)\n",
    "    beta = p_beta0\n",
    "    bn = bayesian_network(mu0, beta, v2, 1, 5, 36, True, mu, sd.to_numpy().flatten())\n",
    "    betas = np.zeros((5, 5, 36))\n",
    "    for i in range(36):\n",
    "        betas[:,:,i] = bn.beta_state[i,:,:]\n",
    "    betaa = np.transpose(bn.beta_action.reshape(36,5))\n",
    "    e = np.sqrt(v2)/200\n",
    "    H = 36\n",
    "    nums = 5\n",
    "    s = np.zeros((nums, H-1))\n",
    "    a = np.zeros(H)\n",
    "    R = np.zeros((H, H, nums, nums))\n",
    "    R0 = np.zeros((H-1, nums, nums))\n",
    "    theta_0 = np.concatenate((theta, np.zeros((nums, 1))), axis = 1)\n",
    "    for i in range(H-1):\n",
    "        coe = np.transpose(betas[:,:,i] + theta_0[:,i].reshape(nums, 1).dot(betaa[:,i].reshape(1, nums)))\n",
    "        R0[i, :, :] = coe.copy()\n",
    "    for i in range(H-1):\n",
    "        R_temp = np.identity(nums)\n",
    "        R[i, i, :, :] = R_temp\n",
    "        for j in range(i+1, H):\n",
    "            R_temp = R0[j-1, :, :].dot(R_temp)\n",
    "            R[i, j, :, :] = R_temp.copy()\n",
    "    R[H-1, H-1, :, :] = np.identity(nums)\n",
    "    shap_s = np.zeros((nums, H, nums, H))\n",
    "    for i in range(H):\n",
    "        for j in range(nums):\n",
    "            indicator = np.zeros(nums)\n",
    "            indicator[j] = 1\n",
    "            for k in range(i, H):\n",
    "                shap_s[j, i, :, k] = R[i, k, :, :].dot(e[j, i]*indicator.reshape(nums, 1)).reshape(nums)\n",
    "    shap_r = np.zeros((nums, H))\n",
    "    alpha = np.zeros((nums, H))\n",
    "    for i in range(H):\n",
    "        alpha[:, i] = (b_r[i] * theta_0[:,i].reshape(nums, 1) + c_r[:, i].reshape(nums, 1)).reshape(nums)\n",
    "    for i in range(nums):\n",
    "        indicator = np.zeros(nums)\n",
    "        indicator[i] = 1\n",
    "        for j in range(H):\n",
    "            for t in range(j, H):\n",
    "                shap_r[i, j] = shap_r[i, j] + alpha[:, t].reshape(1, nums).dot(R[j, t, :, :]).dot(indicator.reshape(nums, 1).dot(e[i, j].reshape(1,1)))\n",
    "    return [shap_r, shap_s]\n",
    "\n",
    "def cal_var_random(s1, p_beta0, v20, theta, b_r, c_r, V_mat):\n",
    "    v2 = v20\n",
    "    beta = p_beta0\n",
    "    bn = bayesian_network(mu0, beta, v2, 1, 5, 36, True, mu, sd.to_numpy().flatten())\n",
    "    betas = np.zeros((5, 5, 36))\n",
    "    for i in range(36):\n",
    "        betas[:,:,i] = bn.beta_state[i,:,:]\n",
    "    betaa = np.transpose(bn.beta_action.reshape(36,5))\n",
    "    k = 0\n",
    "    for i in range(216):\n",
    "        if i%6 != 0:\n",
    "            V_mat[k,k] = v2[i]\n",
    "            k = k+1   \n",
    "    H = 36\n",
    "    nums = 5\n",
    "    theta_0 = np.concatenate((theta, np.zeros((nums, 1))), axis = 1)\n",
    "    R1 = np.zeros((H, H, nums, nums))\n",
    "    R0 = np.zeros((H-1, nums, nums))\n",
    "    for i in range(H-1):\n",
    "        coe = np.transpose(betas[:,:,i] + theta_0[:,i].reshape(nums, 1).dot(betaa[:,i].reshape(1, nums)))\n",
    "        R0[i, :, :] = coe.copy()\n",
    "    for i in range(H-1):\n",
    "        R_temp = np.identity(nums)\n",
    "        R1[i, i, :, :] = R_temp\n",
    "        for j in range(i+1, H):\n",
    "            R_temp = R0[j-1, :, :].dot(R_temp)\n",
    "            R1[i, j, :, :] = R_temp.copy()\n",
    "    R1[H-1, H-1, :, :] = np.identity(nums)\n",
    "    shap_s = np.zeros((nums, H, nums, H))\n",
    "    for i in range(nums):\n",
    "        for j in range(H):\n",
    "            for k in range(j, H):\n",
    "                Rt = np.zeros((nums, (k+1)*nums))\n",
    "                for t in range(k):\n",
    "                    Rt[:, t*nums : (t+1)*nums] = R1[t, k, :, :]\n",
    "                Vt = V_mat[0 : nums*(k+1), 0 : nums*(k+1)]\n",
    "                l = j * nums + i\n",
    "                indicator = np.zeros((nums*(k+1), nums*(k+1)))\n",
    "                indicator[:, l] = 1\n",
    "                shap_s[i, j, :, k] = np.diag(Rt.dot(0.5*Vt*(indicator+indicator.T)).dot(Rt.T))\n",
    "    shap_r = np.zeros((nums, H))\n",
    "    alpha = np.zeros((nums, H))\n",
    "    for i in range(H):\n",
    "        alpha[:, i] = (b_r[i] * theta_0[:,i].reshape(nums, 1) + c_r[:, i].reshape(nums, 1)).reshape(nums)/400\n",
    "    for i in range(nums):\n",
    "        for j in range(H):\n",
    "            shap_r1 = 0\n",
    "            for k in range(j, H):\n",
    "                Rt = np.zeros((nums, (k+1)*nums))\n",
    "                for t in range(k):\n",
    "                    Rt[:, t*nums : (t+1)*nums] = R1[t, k, :, :]\n",
    "                Vt = V_mat[0 : nums*(k+1), 0 : nums*(k+1)]\n",
    "                indicator = np.zeros((nums*(k+1), nums*(k+1)))\n",
    "                l = j * nums + i\n",
    "                indicator[:, l] = 1\n",
    "                shap_r1 = shap_r1 + alpha[:, k].reshape(1, nums).dot(Rt).dot(0.5*Vt*(indicator+indicator.T)).dot(Rt.T).dot(alpha[:, k].reshape(nums, 1))\n",
    "            shap_r2 = 0\n",
    "            for t2 in range(j, H):\n",
    "                Rt2 = np.zeros((nums, (t2+1)*nums))\n",
    "                for t in range(t2):\n",
    "                    Rt2[:, t*nums : (t+1)*nums] = R1[t, t2, :, :]\n",
    "                for t1 in range(j-1):\n",
    "                    Rt1 = np.zeros((nums, (t1+1)*nums))\n",
    "                    for t in range(t1):\n",
    "                        Rt2[:, t*nums : (t+1)*nums] = R1[t, t1, :, :]\n",
    "                    indicator = np.zeros((nums*(t1+1), nums*(t2+1)))\n",
    "                    l = j * nums + i\n",
    "                    indicator[:, l] = 1\n",
    "                    Vt = V_mat[0 : nums*(t1+1), 0 : nums*(t2+1)]\n",
    "                    shap_r2 = shap_r2 + alpha[:, t1].reshape(1, nums).dot(Rt1).dot(0.5*Vt*(indicator)).dot(Rt2.T).dot(alpha[:, t2].reshape(nums, 1))\n",
    "            shap_r3 = 0\n",
    "            for t2 in range(j, H):\n",
    "                Rt2 = np.zeros((nums, (t2+1)*nums))\n",
    "                for t in range(t2):\n",
    "                    Rt2[:, t*nums : (t+1)*nums] = R1[t, t2, :, :]\n",
    "                for t1 in range(j, t2):\n",
    "                    Rt1 = np.zeros((nums, (t1+1)*nums))\n",
    "                    for t in range(t1):\n",
    "                        Rt2[:, t*nums : (t+1)*nums] = R1[t, t1, :, :]\n",
    "                    indicator1 = np.zeros((nums*(t1+1), nums*(t2+1)))\n",
    "                    l = j * nums + i\n",
    "                    indicator1[:, l] = 1\n",
    "                    indicator2 = np.zeros((nums*(t2+1), nums*(t1+1)))\n",
    "                    indicator2[:, l] = 1\n",
    "                    Vt = V_mat[0 : nums*(t1+1), 0 : nums*(t2+1)]\n",
    "                    shap_r3 = shap_r3 + alpha[:, t1].reshape(1, nums).dot(Rt1).dot(0.5*Vt*(indicator1 + indicator2.T)).dot(Rt2.T).dot(alpha[:, t2].reshape(nums, 1))\n",
    "            shap_r[i, j] = shap_r1 + shap_r2 + shap_r3\n",
    "    return [shap_r, shap_s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95c682cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2.7572696208953857\n"
     ]
    }
   ],
   "source": [
    "# predictive analysis for random inputs\n",
    "mu = pd.read_csv('data/mu_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "ssize3 = 1000\n",
    "p_beta, p_v2, mu0 = bn_post.posterior_sample(ssize3, useFixed=False)\n",
    "s1 = np.array([0.00000000e+00,0.00000000e+00,3.00000000e+01,5.00000000e+00,7.00000000e-01])\n",
    "theta = np.load('theta.npy')\n",
    "b_r = np.repeat(-534.52, 36)\n",
    "c_r = np.zeros((5, 36))\n",
    "c_r[1, 35] = 1.29\n",
    "\n",
    "start = time.time()\n",
    "print(1)\n",
    "shap_mean_e_list = []\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "for i in range(ssize3):\n",
    "    shap_mean_e_list.append(pool.apply_async(cal_mean_random, args = (s1, mu0, mu, sd, p_beta[:, :, i], p_v2[:, i], theta, b_r, c_r)))\n",
    "pool.close()\n",
    "pool.join()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "shap_s_mean_e_samples = np.zeros((ssize3, nums, H, nums, H))\n",
    "shap_r_mean_e_samples = np.zeros((ssize3, nums, H))\n",
    "for i in range(ssize3):\n",
    "    shap_r_mean_e_samples[i, :, :] = shap_mean_e_list[i].get()[0]\n",
    "    shap_s_mean_e_samples[i, :, :, :, :] = shap_mean_e_list[i].get()[1]\n",
    "\n",
    "np.save('linear_shap_r_mean_e_samples.npy', shap_r_mean_e_samples)\n",
    "np.save('linear_shap_s_mean_e_samples.npy', shap_s_mean_e_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9deefdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2643.5484766960144\n"
     ]
    }
   ],
   "source": [
    "# variance based analysis for random inputs\n",
    "V_mat = simulate(H = 36, nums = 5, seed = 1)\n",
    "mu = pd.read_csv('data/mu_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "ssize4 = 1000\n",
    "p_beta, p_v2, mu0 = bn_post.posterior_sample(ssize4, useFixed=False)\n",
    "s1 = np.array([0.00000000e+00,0.00000000e+00,3.00000000e+01,5.00000000e+00,7.00000000e-01])\n",
    "theta = np.load('theta.npy')\n",
    "b_r = np.repeat(-534.52, 36)\n",
    "c_r = np.zeros((5, 36))\n",
    "c_r[1, 35] = 1.29\n",
    "\n",
    "start = time.time()\n",
    "print(1)\n",
    "shap_var_e_list = []\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "for i in range(ssize4):\n",
    "    shap_var_e_list.append(pool.apply_async(cal_var_random, args = (s1, p_beta[:,:,i], p_v2[:,i], theta, b_r, c_r, V_mat)))\n",
    "pool.close()\n",
    "pool.join()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "shap_s_var_e_samples = np.zeros((ssize4, nums, H, nums, H))\n",
    "shap_r_var_e_samples = np.zeros((ssize4, nums, H))\n",
    "for i in range(ssize4):\n",
    "    shap_r_var_e_samples[i, :, :] = shap_var_e_list[i].get()[0]\n",
    "    shap_s_var_e_samples[i, :, :, :, :] = shap_var_e_list[i].get()[1]\n",
    "\n",
    "np.save('linear_shap_r_var_e_samples.npy', shap_r_var_e_samples)\n",
    "np.save('linear_shap_s_var_e_samples.npy', shap_s_var_e_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dab625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
